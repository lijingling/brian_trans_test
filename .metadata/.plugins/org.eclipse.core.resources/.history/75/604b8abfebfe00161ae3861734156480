from brian2 import *
import os.path
from struct import unpack
import cPickle as pickle
import time
import numpy as np
import scipy 
import matplotlib.cm as cmap
from brian2tools import *

prefs.codegen.target = 'numpy'

# specify the location of the MNIST data
MNIST_data_path = ''

#------------------------------------------------------------------------------ 
# functions
#------------------------------------------------------------------------------  
def get_labeled_data(picklename, bTrain = True):
    """Read input-vector (image) and target class (label, 0-9) and return
       it as list of tuples.
    """
    if os.path.isfile('%s.pickle' % picklename):
        data = pickle.load(open('%s.pickle' % picklename))
    else:
        # Open the images with gzip in read binary mode
        if bTrain:
            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')
            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')
        else:
            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')
            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')
        # Get metadata for images
        images.read(4)  # skip the magic_number
        number_of_images = unpack('>I', images.read(4))[0]
        rows = unpack('>I', images.read(4))[0]
        cols = unpack('>I', images.read(4))[0]
        # Get metadata for labels
        labels.read(4)  # skip the magic_number
        N = unpack('>I', labels.read(4))[0]
    
        if number_of_images != N:
            raise Exception('number of labels did not match the number of images')
        # Get the data
        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array
        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array
        for i in xrange(N):
            if i % 1000 == 0:
                print("i: %i" % i)
            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in xrange(cols)]  for unused_row in xrange(rows) ]
            y[i] = unpack('>B', labels.read(1))[0]
            
        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}
        pickle.dump(data, open("%s.pickle" % picklename, "wb"))
    return data

def get_matrix_from_file(fileName):
    offset = len(ending) + 4
    if fileName[-4-offset] == 'X':
        n_src = n_input                
    else:
        if fileName[-3-offset]=='e':
            n_src = n_e
        #else:
            #n_src = n_i
    if fileName[-1-offset]=='e':
        n_tgt = n_e
    #else:
       # n_tgt = n_i
    readout = np.load(fileName)
    print readout.shape, fileName
    value_arr = np.zeros((n_src, n_tgt))
    if not readout.shape == (0,):
        value_arr[np.int32(readout[:,0]), np.int32(readout[:,1])] = readout[:,2]
    return value_arr

#------------------------------------------------------------------------------ 
# load MNIST
#------------------------------------------------------------------------------
start = time.time()
training = get_labeled_data(MNIST_data_path + 'training')
end = time.time()
print 'time needed to load training set:', end - start
 
start = time.time()
testing = get_labeled_data(MNIST_data_path + 'testing', bTrain = False)
end = time.time()
print 'time needed to load test set:', end - start

#------------------------------------------------------------------------------ 
# set parameters and equations
#------------------------------------------------------------------------------
test_mode = False

np.random.seed(0)
data_path = './'
if test_mode:
    weight_path = data_path + 'weights/'
    num_examples = 10000 * 1
    use_testing_set = True
    do_plot_performance = False
    record_spikes = True
    ee_STDP_on = False
    update_interval = num_examples
else:
    weight_path = data_path + 'random/'  
    num_examples = 60000 * 3
    use_testing_set = False
    do_plot_performance = True
    if num_examples <= 60000:    
        record_spikes = True
    else:
        record_spikes = True
    ee_STDP_on = True

ending = ''
n_input = 784
n_e = 1

single_example_time =   0.35 * second
resting_time = 0.15 * second
runtime = num_examples * (single_example_time + resting_time)

if num_examples <= 10000:    
    update_interval = num_examples
    weight_update_interval = 20
else:
    update_interval = 10000
    weight_update_interval = 100
    
if num_examples <= 60000:    
    save_connections_interval = 10000
else:
    save_connections_interval = 10000
    update_interval = 10000

v_rest_e = -65. * mV 
v_rest_i = -60. * mV 
v_reset_e = -65. * mV
v_reset_i = -45. * mV
v_thresh_e = -52. * mV
v_thresh_i = -40. * mV
refrac_e = 5. * ms
refrac_i = 2. * ms


###function of e neuron
if test_mode:
    scr_e = 'v = v_reset_e; timer = 0*ms'
else:
    tc_theta = 1e7 * ms
    theta_plus_e = 0.05 * mV
    scr_e = 'v = v_reset_e; theta += theta_plus_e; timer = 0*ms'
offset = 20.0*mV
v_thresh_e = '(v>(theta - offset + ' + str(v_thresh_e) + ')) * (timer>refrac_e)'

neuron_eqs_e = '''
        dv/dt = ((v_rest_e - v) + (I_synE+I_synI) / nS) / (100*ms)  : volt
        I_synE = ge * nS *         -v                           : amp
        I_synI = gi * nS * (-100.*mV-v)                          : amp
        dge/dt = -ge/(1.0*ms)                                   : 1
        dgi/dt = -gi/(2.0*ms)                                  : 1
        '''
if test_mode:
    neuron_eqs_e += '\n  theta      :volt'
else:
    neuron_eqs_e += '\n  dtheta/dt = -theta / (tc_theta)  : volt'
#neuron_eqs_e += '\n  dtimer/dt = 100.0  : ms'

neuron_groups = {}
population_names = ['A']

neuron_groups['e'] = NeuronGroup(n_e*len(population_names), neuron_eqs_e, threshold= v_thresh_e, refractory= refrac_e, reset= scr_e)

#------------------------------------------------------------------------------ 
# create network population and recurrent connections
#------------------------------------------------------------------------------
rate_monitors = {}
spike_counters = {}
spike_monitors = {}
populationnum = 0
for name in population_names:
    print 'create neuron group', name
    neuron_groups[name+'e'] = neuron_groups['e'][n_e*populationnum:n_e*(populationnum+1)]
    neuron_groups[name+'e'].v = v_rest_e - 40. * mV
    neuron_groups['e'].theta = np.ones((n_e)) * 20.0*mV
    

    print 'create monitors for', name
    rate_monitors[name+'e'] = PopulationRateMonitor(neuron_groups[name+'e'])
    spike_counters[name+'e'] = SpikeMonitor(neuron_groups[name+'e'], record=False)
    
    if record_spikes:
        spike_monitors[name+'e'] = SpikeMonitor(neuron_groups[name+'e'])
    populationnum += 1
    
fig_num = 1 
if record_spikes:
    figure(fig_num)
    fig_num += 1
    ion()
    brian_plot(spike_monitors['Ae'])
     
#------------------------------------------------------------------------------ 
# create input population and connections from input populations 
#------------------------------------------------------------------------------  
pop_values = [0,0,0]
input_population_names = ['X']
input_groups = {}
rate_monitors = {}
for i,name in enumerate(input_population_names):
    input_groups[name+'e'] = PoissonGroup(n_input, 0* Hz)
    rate_monitors[name+'e'] = PopulationRateMonitor(input_groups[name+'e'])

input_connection_names = ['XA']
input_conn_names = ['ee_input'] 
connections = {}
delay = {}
delay['ee_input'] = 'rand()*10*ms'
delay['ei_input'] = 'rand()*5*ms'
for name in input_connection_names:
    print 'create connections between', name[0], 'and', name[1]
    for connType in input_conn_names:
        connName = name[0] + connType[0] + name[1] + connType[1]
        weightMatrix = get_matrix_from_file(weight_path + connName + ending + '.npy')
        print weightMatrix.shape
        connections[connName] = Synapses(input_groups[connName[0:2]], neuron_groups[connName[2:4]], 'w : siemens', on_pre='ge += w')
        connections[connName].connect()
        connections[connName].delay = delay[connType]
        connections[connName].w = weightMatrix.flatten() * siemens


